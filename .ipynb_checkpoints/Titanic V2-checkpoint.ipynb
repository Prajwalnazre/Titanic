{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e222f8cc",
   "metadata": {},
   "source": [
    "# Titanic New Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1bf14",
   "metadata": {},
   "source": [
    "### Import Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381d8e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "                         C:\\ProgramData\\anaconda3\n",
      "base                  *  C:\\ProgramData\\anaconda3\\envs\\aiml\n",
      "                         C:\\ProgramData\\anaconda3\\envs\\crisis\n",
      "                         C:\\ProgramData\\anaconda3\\envs\\highres\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc14ae6-891d-4632-9e9c-f31f626ad627",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e9cff6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\_core\\__init__.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\_core\\multiarray.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\_core\\overrides.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     add_docstring,  _get_implementing_args, _ArrayFunctionDispatcher)\n\u001b[0;32m     11\u001b[0m ARRAY_FUNCTIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core._multiarray_umath'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\__init__.py:127\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__config__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_config\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\__config__.py:4\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     __cpu_features__,\n\u001b[0;32m      6\u001b[0m     __cpu_baseline__,\n\u001b[0;32m      7\u001b[0m     __cpu_dispatch__,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_config\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\_core\\__init__.py:49\u001b[0m\n\u001b[0;32m     26\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[0;32m     48\u001b[0m         __version__, exc)\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.12 from \"C:\\ProgramData\\anaconda3\\envs\\aiml\\python.exe\"\n  * The NumPy version is: \"2.2.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy._core._multiarray_umath'\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cell magic for visualization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInlineBackend.figure_format = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretina\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Core imports\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2417\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2419\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2420\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\IPython\\core\\magics\\pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39menable_matplotlib(args\u001b[38;5;241m.\u001b[39mgui\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args\u001b[38;5;241m.\u001b[39mgui, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39mgui)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3588\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3568\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[0;32m   3569\u001b[0m \n\u001b[0;32m   3570\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3586\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[0;32m   3587\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3588\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[0;32m   3590\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m   3591\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\matplotlib_inline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\matplotlib_inline\\backend_inline.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrcsetup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\matplotlib\\cbook.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mweakref\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning  \u001b[38;5;66;03m# numpy >= 1.25\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\aiml\\Lib\\site-packages\\numpy\\__init__.py:132\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    129\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mError importing numpy: you should not try to import numpy from\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124m    its source directory; please exit the numpy source tree, and relaunch\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124m    your python interpreter from there.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _core\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_core\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    136\u001b[0m     False_, ScalarType, True_,\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mabs\u001b[39m, absolute, acos, acosh, add, \u001b[38;5;28mall\u001b[39m, allclose,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m     vecmat, void, vstack, where, zeros, zeros_like\n\u001b[0;32m    183\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
     ]
    }
   ],
   "source": [
    "# Cell magic for visualization\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn as skl\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Optimization\n",
    "import optuna\n",
    "\n",
    "# Interpretation\n",
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3851f0-9479-474a-966e-3a6e6fd9e99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605e62c",
   "metadata": {},
   "source": [
    "### Import training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a3f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv('Datasets/train.csv')\n",
    "test = pd.read_csv('Datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e303d65e-dc59-4c8f-9648-0e5c1f6883bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial checks\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3fcf7-ec0e-4084-8016-349922300ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred_Passenger = test['PassengerId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc267e2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38337f-8454-42c2-b390-78555ee195e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad74673-de1d-4f2d-acb8-adec1236d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the features\n",
    "numerical_features = train.select_dtypes(include=['number'])\n",
    "numerical_features = numerical_features.drop(columns=['Survived','PassengerId','Pclass'])\n",
    "categorical_features = train.select_dtypes(exclude=['number'])\n",
    "categorical_features_pred = test.select_dtypes(exclude=['number'])\n",
    "# categorical_features_pred = categorical_features_pred.to_frame()\n",
    "categorical_features[\"Pclass\"] = train[\"Pclass\"]\n",
    "categorical_features_pred[\"Pclass\"] = test[\"Pclass\"]\n",
    "categorical_features = categorical_features.drop(columns=['Name','Ticket'])\n",
    "categorical_features_pred = categorical_features_pred.drop(columns=['Name','Ticket'])\n",
    "target_column = \"Survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b230a-f2fa-4535-bf6a-807fc19284b7",
   "metadata": {},
   "source": [
    "### Numerical Data Heatmap Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7463d86-acd5-4d88-9c1c-9c59966b049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(numerical_features) :\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = numerical_features.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title('Correlation Heatmap of Numerical Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebc81e-8967-4a59-adfe-cbeaa51a8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2544dd-4127-4d81-8e06-8c399027f02d",
   "metadata": {},
   "source": [
    "### Bar Plots of Numerical Features vs. Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a113b6-7240-4650-8190-46fab55fab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plots_numerical_features(train, numerical_features, target_column) :\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(data=train, x=target_column, y=feature)\n",
    "        plt.title(f'Mean {feature} by {target_column}')\n",
    "        plt.xlabel(target_column)\n",
    "        plt.ylabel(feature)\n",
    "        plt.xticks([0, 1], ['Not Survived', 'Survived']) # Assuming 0 and 1 are your target labels\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfd991-e732-4eed-9ee4-ea33919405cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plots_numerical_features(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b081c-5917-4fc3-9e57-f282f024e747",
   "metadata": {},
   "source": [
    "### Bar Plots of Median Numerical Features vs. Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c4457c-7f2a-43d7-8311-0f3be0319e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plots_numerical_features_median(train, numerical_features, target_column):\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(data=train, x=target_column, y=feature, estimator=np.median)\n",
    "        plt.title(f'Median {feature} by {target_column}')\n",
    "        plt.xlabel(target_column)\n",
    "        plt.ylabel(feature)\n",
    "        plt.xticks([0, 1], ['Negative Class', 'Positive Class'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34daeebf-2946-4d02-b0f2-65a9412f351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plots_numerical_features_median(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72305f62-38f7-4d16-aad4-d48826208c15",
   "metadata": {},
   "source": [
    "### Distribution of Numeric Features with Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1429c-f65c-477d-b239-585199f943df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograms(train, numerical_features, target_column) :\n",
    "    print(\"\\n--- Histograms of Numeric Features ---\")\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(data=train, x=feature, hue=target_column, kde=False, multiple=\"stack\")\n",
    "        plt.title(f'Histogram of {feature} by {target_column}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend(title=target_column, labels=['No', 'Yes']) # Assuming 0 is 'No', 1 is 'Yes'\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ba92c-0add-44ff-9d63-0d850809b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0d683b-942d-4ab2-a399-8a965ddb5fac",
   "metadata": {},
   "source": [
    "### Distribution of Numeric Features with KDE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d21cbe4-44f4-4dc1-8469-5a28b0c9d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_plots(train, numerical_features, target_column) :\n",
    "    print(\"\\n--- KDE Plots of Numeric Features ---\")\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.kdeplot(data=train, x=feature, hue=target_column, fill=True, alpha=.5, multiple=\"stack\")\n",
    "        plt.title(f'KDE Plot of {feature} by {target_column}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend(title=target_column, labels=['No', 'Yes']) # Assuming 0 is 'No', 1 is 'Yes'\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0d227-1572-42b8-8d72-baad54409ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074c4b2-9c5b-4f98-a071-5716d8b678ce",
   "metadata": {},
   "source": [
    "### Combined Histograms and KDE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17446ff-37af-4dc3-980c-ebb62c8de356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def historgram_kde_plots(train, numerical_features, target_column) :\n",
    "    print(\"\\n--- Combined Histograms and KDE Plots of Numeric Features ---\")\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=train, x=feature, hue=target_column, kde=True, multiple=\"stack\")\n",
    "        plt.title(f'Histogram and KDE of {feature} by {target_column}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Density / Frequency')\n",
    "        plt.legend(title=target_column, labels=['No', 'Yes']) # Assuming 0 is 'No', 1 is 'Yes'\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc7a62-5b8e-4056-8db1-29573037205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "historgram_kde_plots(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ed206-e9f8-458b-ae94-c8c640ba605f",
   "metadata": {},
   "source": [
    "### Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a908042-2740-48d3-98bf-0fb3810ad4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_plits(train) :\n",
    "    sns.pairplot(train[['Survived', 'Pclass', 'Age', 'Fare', 'SibSp', 'Parch']], hue='Survived')\n",
    "    plt.suptitle('Pairwise Relationships of Features', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053f4ff-b7e1-41ae-b617-12ee9932bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plits(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebf7c9-22f9-46e7-8f06-2addd8afb4d7",
   "metadata": {},
   "source": [
    "### Target vs. Numerical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aee6e1-1f6f-4b95-8354-a4096716648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target vs. Numerical Feature Analysis ---\n",
    "\n",
    "def box_plots_numerical_features(train, numerical_features, target_column) :\n",
    "\n",
    "    print(\"--- Boxplots of Numerical Features by Target ---\")\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.boxplot(data=train, x=target_column, y=feature, hue=target_column)\n",
    "        plt.title(f'Boxplot of {feature} by {target_column}')\n",
    "        plt.xlabel(target_column)\n",
    "        plt.ylabel(feature)\n",
    "        plt.xticks([0, 1], ['Negative Class', 'Positive Class'])\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n--- Violin Plots of Numerical Features by Target ---\")\n",
    "    for feature in numerical_features:\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.violinplot(data=train, x=target_column, y=feature, split=True, inner=\"quart\")\n",
    "        plt.title(f'Violin Plot of {feature} by {target_column}')\n",
    "        plt.xlabel(target_column)\n",
    "        plt.ylabel(feature)\n",
    "        plt.xticks([0, 1], ['Negative Class', 'Positive Class'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a9c40-22e3-4cc2-a24a-c543571873f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plots_numerical_features(train, numerical_features, target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f0ebfd-4275-485a-b1f8-b311856f0d09",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4374ed56-c6e1-46cf-b19b-813dc8faf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all the unique titles from the dataset\n",
    "\n",
    "all_titles = []\n",
    "\n",
    "for name_string in train[\"Name\"] :\n",
    "    comma_pos = name_string.find(',')\n",
    "    dot_pos = name_string.find('.')\n",
    "    title = name_string[comma_pos + 2:dot_pos]\n",
    "    if title not in all_titles :\n",
    "        all_titles.append(title)\n",
    "\n",
    "print(all_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9dc73a-62dd-4c76-be8b-150c9ade07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the title for a given name\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            return substring\n",
    "    # print(big_string)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46626788-4bb0-4165-9563-4690bc2d46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalute the above function to each row and add it as a column\n",
    "\n",
    "train['Title']=train['Name'].map(lambda x: substrings_in_string(x, all_titles))\n",
    "test['Title']=test['Name'].map(lambda x: substrings_in_string(x, all_titles))\n",
    "\n",
    "#replacing all titles with mr, mrs, miss, master\n",
    "def replace_titles(x):\n",
    "    title=x['Title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n",
    "        return 'Rare_Mr'\n",
    "    elif title in ['Countess', 'Mme']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "train['Title']=train.apply(replace_titles, axis=1)\n",
    "test['Title']=test.apply(replace_titles, axis=1)\n",
    "\n",
    "categorical_features['Title'] = train['Title']\n",
    "categorical_features_pred['Title'] = test['Title']\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bb06d-898b-40fe-a80c-9b91b5ac4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a4129-1b39-4624-a392-f03f1fc4279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning cabin number into Deck\n",
    "cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'NaN']\n",
    "\n",
    "train['Deck']=train['Cabin'].map(lambda x: substrings_in_string(str(x), cabin_list))\n",
    "test['Deck']=test['Cabin'].map(lambda x: substrings_in_string(str(x), cabin_list))\n",
    "\n",
    "categorical_features['Deck'] = train['Deck']\n",
    "categorical_features_pred['Deck'] = test['Deck']\n",
    "print(train['Deck'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83d5b71-26b4-4459-978c-3208703cc64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a66979-b794-45da-aaef-23da450980ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new family_size column\n",
    "train['Family_Size']=train['SibSp']+train['Parch']+1\n",
    "test['Family_Size']=test['SibSp']+test['Parch']+1\n",
    "numerical_features['Family_Size'] = train['Family_Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28f053-11fd-4568-9fbd-1c9188645497",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084a646-56c7-4583-abcc-d5d209294869",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = categorical_features.drop(columns = ['Cabin','Deck'])\n",
    "categorical_features_pred = categorical_features_pred.drop(columns = ['Cabin','Deck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443bc0f-59df-43dc-a5bd-7c6b1f9097b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf5aef-bfa1-4322-bd0c-591479f6fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_pred.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d8b6f-4aba-4d8b-896c-9c2747038960",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9b520-98a2-43e4-b9e1-89099c587807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22036d0-f496-4faa-90c2-e46dc0e94d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['Name','Ticket','PassengerId','Cabin','Deck'])\n",
    "test = test.drop(columns = ['Name','Ticket','PassengerId','Cabin','Deck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074aed8-e60f-42ef-922b-f551083c69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8766d9-a38f-4934-b200-1afb7f409f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25235b7-8811-445e-b0b0-13d73f7e5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_features(categorical_features) :\n",
    "    # label_encoders = {}\n",
    "    X_encoded = categorical_features.copy()\n",
    "    i = 0\n",
    "    for col in categorical_features:\n",
    "        print(categorical_features.columns[i])\n",
    "        # le = skl.preprocessing.LabelEncoder()\n",
    "        # X_encoded[col] = le.fit_transform(X_encoded[col])\n",
    "        # label_encoders[col] = le\n",
    "        X_encoded_dummies = pd.get_dummies(categorical_features[col], prefix=categorical_features.columns[i])\n",
    "        X_encoded = pd.concat([X_encoded, X_encoded_dummies], axis=1)\n",
    "        X_encoded.drop(col, axis=1, inplace=True)\n",
    "        i += 1\n",
    "        \n",
    "    return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4b74c-c762-4bdf-8bab-0b32ce91f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(categorical_features_pred))\n",
    "# categorical_features_pred = categorical_features_pred.to_frame()\n",
    "# print(type(categorical_features_pred))\n",
    "# categorical_features_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9fdd9e-3b62-48cb-a0e1-040389902ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([target_column], axis=1)\n",
    "X_Pred = test\n",
    "print(type(X_Pred))\n",
    "y = train[target_column]\n",
    "categorical_features_encoded = encode_categorical_features(categorical_features)\n",
    "categorical_features_encoded_pred = encode_categorical_features(categorical_features_pred)\n",
    "categorical_features_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ae8fc-08db-488c-9f0b-e799aca575b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train, categorical_features_encoded], axis=1)\n",
    "X_Pred = pd.concat([test, categorical_features_encoded_pred], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8df36b-5c5a-4950-83a4-dca90ae781e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new feature Is_Alone\n",
    "\n",
    "X['Is_Alone'] = False\n",
    "X.loc[X['Family_Size'] == 1, 'Is_Alone'] = True\n",
    "\n",
    "X_Pred['Is_Alone'] = False\n",
    "X_Pred.loc[X_Pred['Family_Size'] == 1, 'Is_Alone'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6a722-1299-4f15-bbfa-c974b1170795",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3ffa8-e2a2-49d3-ac4d-975fb6d04227",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb884813-1122-4021-ac08-2483fad8d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age_Missing'] = X['Age'].isnull().astype(int)\n",
    "X_Pred['Age_Missing'] = X_Pred['Age'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe2892-ec31-435c-a879-dc3b8291dd25",
   "metadata": {},
   "source": [
    "Impute with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb9a759-2948-4793-950c-c03907961268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handling the missing values\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# def impute_age(cols):\n",
    "#     Age = cols[0]\n",
    "#     Pclass = cols[1]\n",
    "\n",
    "#     if pd.isnull(Age):\n",
    "#         if Pclass == 1:\n",
    "#             return X[X['Pclass'] == 1]['Age'].median()\n",
    "#         elif Pclass == 2:\n",
    "#             return X[X['Pclass'] == 2]['Age'].median()\n",
    "#         else:\n",
    "#             return X[X['Pclass'] == 3]['Age'].median()\n",
    "#     return Age\n",
    "\n",
    "# X['Age'] = X[['Age', 'Pclass']].apply(impute_age, axis=1)\n",
    "# X_Pred['Age'] = X_Pred[['Age', 'Pclass']].apply(impute_age, axis=1)\n",
    "\n",
    "# print(f\"Number of NaN values in Age after Pclass-based imputation: {X['Age'].isna().sum()}\")\n",
    "# print(f\"Number of NaN values in Age after Pclass-based imputation: {X_Pred['Age'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6a4af-c6cf-4fb5-8219-75e8965b96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(columns=['Survived','Sex','Pclass','Title'])\n",
    "# X_Pred = X_Pred.drop(columns=['Sex','Pclass','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a59ee1-afc8-4991-89b6-3cfa27e64d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get indices of rows with missing 'Embarked' values\n",
    "# dropped_indices = X[X['Embarked'].isna()].index\n",
    "\n",
    "# # Drop rows from X\n",
    "# X.dropna(subset=['Embarked'], inplace=True)\n",
    "\n",
    "# # Drop corresponding rows from y using the same indices\n",
    "# y.drop(index=dropped_indices, inplace=True)\n",
    "# categorical_features_encoded.drop(index=dropped_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df61b1b-03f1-4f1c-badc-b04035ad5780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(columns=['Embarked'])\n",
    "# X_Pred = X_Pred.drop(columns=['Embarked'])\n",
    "# X.drop(columns=['Title_the Countess'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39ce87-7b3f-42dd-a514-5037f1132e9a",
   "metadata": {},
   "source": [
    "Using Regression for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f786477-841a-4581-9280-1cd5e3b5e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Embarked with mode\n",
    "\n",
    "X['Embarked'] = X['Embarked'].fillna(X['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a364eb-f38c-4694-aab2-e8c2b2150e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(columns=['Title_the Countess'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111c830-1c89-4131-84a0-8e236ce02456",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Survived','Sex','Embarked','Pclass','Title'])\n",
    "X_Pred = X_Pred.drop(columns=['Sex','Embarked','Pclass','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13936c81-3587-4ee8-a119-91adacb365f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Values using Random Forest Regression\n",
    "\n",
    "def impute_age(X, X_Pred) :\n",
    "    \n",
    "    Known_Age_X = X[X['Age'].notnull()]\n",
    "    Unknown_Age_X = X[X['Age'].isnull()]\n",
    "    Unknown_Age_X_Pred = X_Pred[X_Pred['Age'].isnull()]\n",
    "    \n",
    "    Known_Age_y = Known_Age_X['Age']\n",
    "    Known_Age_X.drop(columns=['Age'], inplace=True)\n",
    "    Unknown_Age_X.drop(columns=['Age'], inplace=True)\n",
    "    Unknown_Age_X_Pred.drop(columns=['Age'], inplace=True)\n",
    "    \n",
    "    print(\"\\nTraining RandomForestRegressor to predict missing 'Age' values...\")\n",
    "    rfr = skl.ensemble.RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rfr.fit(Known_Age_X, Known_Age_y)\n",
    "    print(\"Training complete.\")\n",
    "    predicted_ages_X = rfr.predict(Unknown_Age_X)\n",
    "    X.loc[X['Age'].isnull(), 'Age'] = predicted_ages_X\n",
    "\n",
    "    predicted_ages_X_Pred = rfr.predict(Unknown_Age_X_Pred)\n",
    "    X_Pred.loc[X_Pred['Age'].isnull(), 'Age'] = predicted_ages_X_Pred\n",
    "    \n",
    "    print(\"\\nMissing Age values after imputation:\", X['Age'].isnull().sum())\n",
    "    print(\"Shape of X after age imputation:\", X.shape)\n",
    "\n",
    "    print(\"\\nMissing Age values after imputation:\", X_Pred['Age'].isnull().sum())\n",
    "    print(\"Shape of X_Pred after age imputation:\", X_Pred.shape)\n",
    "\n",
    "impute_age(X, X_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a024795-85b3-47ec-81df-9dcc2e579439",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfff2a4-5d40-4600-af4b-6d51e27795cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600dfe4-c782-49b8-b1f9-f1643850740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing 'Fare' with mean\n",
    "\n",
    "X_Pred['Fare'] = X_Pred['Fare'].fillna(X_Pred['Fare'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3272177-b211-4192-a771-fc24ae89ebe3",
   "metadata": {},
   "source": [
    "### Mutual Information Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c540c2-092f-423f-bead-aee7d7087d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y.index.equals(X.index))  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ec5e7-10d6-48bc-8e71-a25746a92b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_Pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47bb79-fba8-4a6b-ae0f-12854eee8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information_scores(X, y) :\n",
    "    # Calculate Mutual Information Scores\n",
    "    mutual_info = skl.feature_selection.mutual_info_classif(categorical_features_encoded, y, random_state=42)\n",
    "    \n",
    "    # Create a Series of Feature Names and their MI Scores\n",
    "    mi_scores = pd.Series(mutual_info, index=categorical_features_encoded.columns)\n",
    "    \n",
    "    # Sort the MI scores in descending order\n",
    "    mi_scores_sorted = mi_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Display the Mutual Information Scores\n",
    "    print(\"--- Feature-Target Mutual Information Scores ---\")\n",
    "    print(mi_scores_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96c3ac-3351-4271-b1d0-6e0f72487987",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information_scores(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78376835-5c70-4c9d-82b5-6072ffee34b5",
   "metadata": {},
   "source": [
    "### Target vs. Categorical Feature Analysis (using Barplots for proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5165588-d2e0-4cfd-8a8d-7430cd740a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plots_categorical_features(train, categorical_features, target_column) :\n",
    "    print(\"\\n--- Bar Plots of Target Proportions by Categorical Features ---\")\n",
    "    for feature in categorical_features:\n",
    "        category_proportions = train.groupby(feature)[target_column].value_counts(normalize=True).mul(100).rename('Percentage').reset_index()\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.barplot(data=category_proportions, x=feature, y='Percentage', hue=target_column)\n",
    "        plt.title(f'Proportion of {target_column} by {feature}')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Percentage (%)')\n",
    "        plt.legend(title=target_column, labels=['Negative Class', 'Positive Class'])\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76dd78c-4c9e-42ce-bd31-598d949429f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plots_categorical_features(train, categorical_features, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d2a46-fb09-435d-9cd5-e6701b44a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5cd8e-41a0-4ae6-8308-ed48efa18e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.drop(columns=['Survived','Sex','Embarked','Pclass','Title'])\n",
    "# X_Pred = X_Pred.drop(columns=['Sex','Embarked','Pclass','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db1aa-474c-4752-9e40-7330508306af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f08006-40f3-4918-9764-bfa2231eed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f4024-8fce-456b-b13d-1a7e5e734aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfdb74b-3424-4caa-b7b1-cb005a893ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping the Outliers\n",
    "\n",
    "lower_limit_age = X['Age'].quantile(0.05)  # 5th percentile\n",
    "upper_limit_age = X['Age'].quantile(0.95)  # 95th percentile\n",
    "X['Age'] = np.clip(X['Age'], lower_limit_age, upper_limit_age)\n",
    "X_Pred['Age'] = np.clip(X_Pred['Age'], lower_limit_age, upper_limit_age)\n",
    "print(\"Capping the Age between \" + lower_limit_age + \" and \" + upper_limit_age)\n",
    "\n",
    "lower_limit_sibsp = X['SibSp'].quantile(0.05)  # 5th percentile\n",
    "upper_limit_sibsp = X['SibSp'].quantile(0.95)  # 95th percentile\n",
    "X['SibSp'] = np.clip(X['SibSp'], lower_limit_sibsp, upper_limit_sibsp)\n",
    "X_Pred['SibSp'] = np.clip(X_Pred['SibSp'], lower_limit_sibsp, upper_limit_sibsp)\n",
    "print(\"Capping the SibSp between \" + lower_limit_sibsp + \" and \" + upper_limit_sibsp)\n",
    "\n",
    "lower_limit_parch = X['Parch'].quantile(0.05)  # 5th percentile\n",
    "upper_limit_parch = X['Parch'].quantile(0.95)  # 95th percentile\n",
    "X['Parch'] = np.clip(X['Parch'], lower_limit_parch, upper_limit_parch)\n",
    "X_Pred['Parch'] = np.clip(X_Pred['Parch'], lower_limit_parch, upper_limit_parch)\n",
    "print(\"Capping the Parch between \" + lower_limit_parch + \" and \" + upper_limit_parch)\n",
    "\n",
    "lower_limit_fare = X['Fare'].quantile(0.05)  # 5th percentile\n",
    "upper_limit_fare = X['Fare'].quantile(0.95)  # 95th percentile\n",
    "X['Fare'] = np.clip(X['Fare'], lower_limit_fare, upper_limit_fare)\n",
    "X_Pred['Fare'] = np.clip(X_Pred['Fare'], lower_limit_fare, upper_limit_fare)\n",
    "print(\"Capping the Fare between \" + lower_limit_fare + \" and \" + upper_limit_fare)\n",
    "\n",
    "lower_limit_family_size = X['Family_Size'].quantile(0.05)  # 5th percentile\n",
    "upper_limit_family_size = X['Family_Size'].quantile(0.95)  # 95th percentile\n",
    "X['Family_Size'] = np.clip(X['Family_Size'], lower_limit_family_size, upper_limit_family_size)\n",
    "X_Pred['Family_Size'] = np.clip(X_Pred['Family_Size'], lower_limit_family_size, upper_limit_family_size)\n",
    "print(\"Capping the Family Size between \" + lower_limit_family_size + \" and \" + upper_limit_family_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b646a02-a73d-4457-baf5-a80b0ce8d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = skl.preprocessing.StandardScaler()\n",
    "X[['Age','SibSp','Parch','Fare','Family_Size']] = scaler.fit_transform(X[['Age','SibSp','Parch','Fare','Family_Size']])\n",
    "# X_Pred[['Age','SibSp','Parch','Fare','Family_Size']] = scaler.fit_transform(X_Pred[['Age','SibSp','Parch','Fare','Family_Size']])\n",
    "\n",
    "with open(\"standard_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "X_Pred[['Age','SibSp','Parch','Fare','Family_Size']] = scaler.transform(X_Pred[['Age','SibSp','Parch','Fare','Family_Size']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b26db49-489d-402a-860c-020d806a4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a9f3c-61b2-42f1-90d2-6def49e7d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ef801-1f48-4995-a73c-bea6bd211687",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6eae59-a236-4517-9538-b92dc4b929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd650c-ca6b-4090-b5b7-90c91c1ef6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d1d49-8d21-406b-bcf4-6fe03db5e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define StratifiedKFold\n",
    "skf = skl.model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db45e570-a971-4283-a95a-942433c5c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize folds\n",
    "def plot_folds(folds, method_name, y_labels):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for i, (train_idx, test_idx) in enumerate(folds.split(X_train, y_labels)):\n",
    "        plt.scatter(test_idx, [i] * len(test_idx), label=f\"Fold {i+1}\", alpha=0.7)\n",
    "    plt.yticks(range(5), [f\"Fold {i+1}\" for i in range(5)])\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Fold Number\")\n",
    "    plt.title(f\"{method_name} Class Distribution\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize StratifiedKFold before model optimization\n",
    "plot_folds(skf, \"StratifiedKFold\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b25f2f-f2cf-4c8a-a6c1-d1713471fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86867aa6-6281-4347-bf09-f3ec9440601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(trial, model_type):\n",
    "    params = {}\n",
    "    \n",
    "    if model_type == \"Logistic Regression\":\n",
    "        params = {\n",
    "            \"C\": trial.suggest_loguniform(\"C\", 1e-3, 10),\n",
    "            \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l2\"]),\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"saga\", \"newton-cg\"]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        model = skl.linear_model.LogisticRegression(**params)\n",
    "\n",
    "    elif model_type == \"Decision Tree\":\n",
    "        params = {\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 2, 30),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"]),\n",
    "            \"random_state\": 42\n",
    "        }\n",
    "        model = skl.tree.DecisionTreeClassifier(**params)\n",
    "\n",
    "    elif model_type == \"Random Forest\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "            \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "            \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        model = skl.ensemble.RandomForestClassifier(**params)\n",
    "\n",
    "    elif model_type == \"XGBoost\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "            \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 10.0),\n",
    "            \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
    "            \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
    "            \"use_label_encoder\": False,\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"n_jobs\": -1,\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "    elif model_type == \"LightGBM\":\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 7, 512),\n",
    "            \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "            \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n",
    "            \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        model = LGBMClassifier(**params)\n",
    "\n",
    "    elif model_type == \"CatBoost\":\n",
    "        params = {\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 100, 1000),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "            \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-3, 10.0),\n",
    "            \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "            \"random_strength\": trial.suggest_uniform(\"random_strength\", 1e-9, 10.0),\n",
    "            \"verbose\": 0,\n",
    "            \"random_seed\": 42,\n",
    "        }\n",
    "        model = CatBoostClassifier(**params)\n",
    "\n",
    "    # score = skl.model_selection.cross_val_score(\n",
    "    #     model, X_train, y_train, cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    "    # )\n",
    "    \n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        accuracies.append(model.score(X_test_fold, y_test_fold))\n",
    "\n",
    "    return np.mean(accuracies)\n",
    "    \n",
    "    # return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06473582-43f8-4095-a90d-ee3c497f366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize each model\n",
    "\n",
    "optimized_models = {}\n",
    "for model_name in [\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"XGBoost\",\n",
    "    # \"LightGBM\",\n",
    "    \"CatBoost\"\n",
    "]:\n",
    "    print(f\"Optimizing {model_name}...\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: optimize_model(trial, model_name), n_trials=20, show_progress_bar=True)\n",
    "    optimized_models[model_name] = study.best_params\n",
    "    print(f\"Best params for {model_name}: {study.best_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a441b9-3a7c-4edf-97b8-f3070be2e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = skl.ensemble.RandomForestClassifier(**optimized_models[\"Random Forest\"])\n",
    "meta_model = skl.linear_model.LogisticRegression(**optimized_models[\"Logistic Regression\"])\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": skl.linear_model.LogisticRegression(**optimized_models[\"Logistic Regression\"]),\n",
    "    \"Decision Tree\": skl.tree.DecisionTreeClassifier(**optimized_models[\"Decision Tree\"]),\n",
    "    \"Random Forest\": skl.ensemble.RandomForestClassifier(**optimized_models[\"Random Forest\"]),\n",
    "    \"XGBoost\": XGBClassifier(**optimized_models[\"XGBoost\"]),\n",
    "    # \"LightGBM\": LGBMClassifier(**optimized_models[\"LightGBM\"], verbose=-1),\n",
    "    \"CatBoost\": CatBoostClassifier(**optimized_models[\"CatBoost\"], verbose=0),\n",
    "    \"Stacked Model\": skl.ensemble.StackingClassifier(\n",
    "        estimators=[(\"rf\", base_model)],\n",
    "        final_estimator=meta_model,\n",
    "        cv=5  # Stratified cross-validation\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8653a04-968a-4676-83e0-b32560d3349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = skl.ensemble.RandomForestClassifier(**optimized_models[\"Random Forest\"])\n",
    "# meta_model = skl.linear_model.LogisticRegression(**optimized_models[\"Logistic Regression\"])\n",
    "\n",
    "# # Implement stacking\n",
    "# stacked_model = skl.ensemble.StackingClassifier(\n",
    "#     estimators=[(\"rf\", base_model)],\n",
    "#     final_estimator=meta_model,\n",
    "#     cv=5  # Stratified cross-validation\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6a9f4-dce0-4090-9b2a-e4f80dd26d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select best-performing model (replace with actual best model)\n",
    "# best_model = models[\"XGBoost\"]  # Example\n",
    "\n",
    "# # Fit SHAP explainer\n",
    "# explainer = shap.Explainer(best_model, X_train)\n",
    "# shap_values = explainer(X_test)\n",
    "\n",
    "# # Plot feature importance\n",
    "# shap.summary_plot(shap_values, X_test, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916eafff-2632-46ce-8aa6-336f5a3679de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3891a2f-9498-4635-9d5a-575e01c077b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred['Fare'].fillna(X_Pred['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64992bc9-d5d3-4f4f-8672-368db483259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fd0f8-c51b-4561-9733-678c0dac1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Pred_Passenger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d294370-0d68-45b3-9237-d50d7e2d2bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = skl.metrics.accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86fbf8-b8b5-44fe-98e7-bd1f312ea1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = X_test.select_dtypes(include=['bool']).columns\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)\n",
    "X_train[bool_cols] = X_train[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef7cc3-b896-44b1-af7a-2d0ccaabbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88ffee-e0b4-401f-b0ad-f2c6d727db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SHAP\n",
    "explainer = shap.Explainer(models[\"Random Forest\"], X_train)\n",
    "shap_values = explainer(X_test) # This is the full Explanation object\n",
    "print(shap_values.shape)\n",
    "\n",
    "# Visualize feature importance\n",
    "print(f\"SHAP Summary for Random Forest\")\n",
    "\n",
    "# shap.summary_plot(shap_values, X_test)\n",
    "print(\"Survival Dependence\")\n",
    "shap.plots.beeswarm(shap_values[..., 1])  # Select SHAP values for the survival class\n",
    "print(\"Non-Survival Dependence\")\n",
    "shap.plots.beeswarm(shap_values[..., 0])  # Select SHAP values for the non-survival class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f55c4e-f6fe-4e2f-abe4-2c43cb4eeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all trained models and save predictions separately\n",
    "for model_name, model in models.items():\n",
    "    predictions = model.predict(X_Pred)  # Generate predictions using X_Pred\n",
    "\n",
    "    # Create a submission DataFrame with required format\n",
    "    submission_df = pd.DataFrame({\"PassengerId\": X_Pred_Passenger, \"Survived\": predictions})\n",
    "\n",
    "    # Save each models predictions as a separate CSV file\n",
    "    filename = f\"{model_name}_submission.csv\"\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4533ebf0-5193-4a6e-8439-0884e9afdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(models[\"Random Forest\"], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
